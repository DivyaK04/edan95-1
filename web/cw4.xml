<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC
        "-//W3C//DTD XHTML 1.0 Strict//EN"
        "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xml:lang="en" xmlns="http://www.w3.org/1999/xhtml">
    <head>
        <title>Assignment #4: Recurrent Neural Networks</title>
    </head>
    <body>
        <!--<h1>Assignment #4: Recurrent Neural Networks</h1>-->
        <h2>Provisional</h2>
        <p>The content of this page is provisional and will possibly change by the day of the lab.</p>
        <h2>Objectives</h2>
        <p>The objectives of this assignment are to:</p>
        <ul>
            <li>Write a program to recognize named entities in text</li>
            <li>Learn how to manage a text data set</li>
            <li>Apply recurrent neural networks to text</li>
            <li>Know what word embeddings are</li>
        </ul>
        <h2>Organization and location</h2>
        <p>The third lab session will take place on</p>
        <ul>
            <li>Group 1: Thursday, November 29 from 13:15 to 15:00 in the Alpha room</li>
            <li>Group 2: Thursday, November 29 from 13:15 to 15:00 in the Beta room</li>
            <li>Group 3: Friday, November 30 from 13:15 to 15:00 in the Alpha room</li>
        </ul>
        <p>Always check the calender for last minute changes:
            <a href="https://cloud.timeedit.net/lu/web/lth1/ri1Xp0gQ4560YZQQ85Z697wY0Zy70073Q5o53Q664v54rZo0xoQY.html#">
                https://cloud.timeedit.net/lu/web/lth1/ri1Xp0gQ4560YZQQ85Z697wY0Zy70073Q5o53Q664v54rZo0xoQY.html#
            </a>
        </p>
        <p>You can work alone or collaborate with another student:</p>
        <ul>
            <li>Each group will have to write Python programs to recognize named entities in text.
            </li>
            <li>You will have to experiment different architectures, namely RNN and LSTM,
                and compare the results you obtained.
            </li>
        </ul>
        <h2>Programming</h2>
        <h3>Collecting a Dataset</h3>
        <ol>
            <li>You will use a dataset from the CoNLL conferences that benchmark natural language processing systems and
                tasks.
                There were two conferences on named entity recognition:
                <a href="https://www.clips.uantwerpen.be/conll2003/ner/">CoNLL 2002</a>
                (Spanish and Dutch)
                and <a href="https://www.clips.uantwerpen.be/conll2002/ner/">CoNLL 2003</a> (English and German). In
                this
                assignment, you will work on the English dataset. Read the description of the task.
            </li>
            <li>
                The datasets are protected by a license and you need to obtain it to reconstruct the data.
                Alternatively, you can use a local copy or try to find one on github (type conll2003 in the search box)
                or use the Google dataset search:
                <a href="https://toolbox.google.com/datasetsearch">https://toolbox.google.com/datasetsearch</a>.
                You can find a local copy in the <tt>/usr/local/cs/EDAN95/datasets/NER-data</tt> folder.
            </li>
            <li>The dataset comes in the form of three files: a training set, a development set, and a test set.
                <!--, named:
                <tt>eng.train</tt>, <tt>eng.testa</tt> (validation), and <tt>eng.testb</tt> (test).-->
                You will use the test set to evaluate your models. For this, you will
                apply the <tt>conlleval</tt> script that will compute the harmonic mean of the precision and recall: F1.
                You have a local copy of this script in <tt>/usr/local/cs/EDAN95/datasets/ner/bin</tt>. <tt>conlleval
                </tt> is
                written in Perl. Be sure to have it on your machine to run it.
            </li>
        </ol>
        <h3>Collecting the Embeddings</h3>
        <ol>
            <li>
                Download the GloVe embeddings 6B from
                <a href="https://nlp.stanford.edu/projects/glove/">
                    https://nlp.stanford.edu/projects/glove/
                </a>
                and keep the 100d vectors.
            </li>
            <li>Write a function that reads GloVe embeddings and store them in a dictionary,
                where the keys will be the words and the values, the embeddings.
            </li>
            <li>Using a cosine similarity, compute the 5 closest words to the words <i>table</i>, <i>france</i>,
                and <i>sweden</i>.
            </li>
        </ol>
        <h3>Reading the Corpus and Building Indices</h3>
        <p>You will read the corpus with programs available from
            <a href="https://github.com/pnugues/edan95">https://github.com/pnugues/edan95</a>. These
            programs will enable you to load the files in the form of a list of dictionaries.
        </p>
        <ol>
            <li>Write a function that for each sentence
                returns the <b>X</b> and <b>Y</b> lists of symbols consisting of words and NER tags.
            </li>
            <li>
                Create a vocabulary of all the words
                observed in the training set and the words in GloVe.
            </li>
            <li>Create indices and inverted indices for the words and the NER: i.e. you
                will associate each word with a number.
                You will use index 0 for the padding symbol and 1 for unknown words.
            </li>
        </ol>
        <h3>Building the Embedding Matrix</h3>
        <ol>
            <li>Create a matrix whose size will be that of all the words:
                The unique words in the training set and the words in GloVe.
                Initialize it with random values.
            </li>
            <li>Fill the matrix with the GloVe embeddings.
                You will use the indices from the previous section.
            </li>
        </ol>
        <h3>Creating the <b>X</b> and <b>Y</b> Sequences
        </h3>
        <p>You will now create the input and output sequences with numerical indices</p>
        <ol>
            <li>Convert the <b>X</b> and <b>Y</b> list of symbols in a list of numbers using the indices
                you created.
            </li>
            <li>Pad the sentences using the <tt>pad_sequences</tt> function.
            </li>
            <li>Do the same for the development set.</li>
        </ol>
        <h3>Building a Simple Recurrent Neural Network</h3>
        <ol>
            <li>Create a simple recurrent network and train a model with the train set.
                As layers, you will use <tt>Embedding</tt>, <tt>SimpleRNN</tt>, and <tt>Dense</tt>.
            </li>
            <li>Compile and fit your network. You will report the training and validation losses and accuracies and
                comment on the possible overfit.
            </li>
            <li>Apply your network to the test set and report the accuracy you obtained.
                You will use the <tt>evaluate</tt> method.
            </li>
        </ol>
        <h3>Evaluating your System</h3>
        <p>You will use the official script to evaluate the performance of your system</p>
        <ol>
            <li>Use the <tt>predict</tt> method to predict the tags of the whole test set
            </li>
            <li>Write your results in a file, where the two last columns will be the hand-annotated tag
                and the predicted tag. The fields must be separated by a space.
            </li>
            <li>Apply conlleval to your output. Report the F1 result.</li>
            <li>Try to improve your model by modifying some parameters, adding layers, adding
                <tt>Bidirectional</tt>
                and <tt>Dropout</tt>.
            </li>
            <li>
                Evaluate your network again
            </li>
        </ol>
        <h3>Building a LSTM Network</h3>
        <ol>
            <li>Create a simple LSTM network and train a model with the train set.
                As layers, you will use <tt>Embedding</tt>, <tt>LSTM</tt>, and <tt>Dense</tt>.
            </li>
            <li>Apply conlleval to your output. Report the F1 result.</li>
            <li>Try to improve your model by modifying some parameters, adding layers, adding
                <tt>Bidirectional</tt>, <tt>Dropout</tt>, possibly mixing <tt>SimpleRNN</tt>.
            </li>
            <li>
                Apply your network to the test set and report the accuracy you obtained.
                you need to reach a F1 of 82 to pass.
            </li>
        </ol>
    </body>
</html>
