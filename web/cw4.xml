<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC
        "-//W3C//DTD XHTML 1.0 Strict//EN"
        "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xml:lang="en" xmlns="http://www.w3.org/1999/xhtml">
    <head>
        <title>Assignment #4: Recurrent Neural Networks</title>
    </head>
    <body>
        <!--<h1>Assignment #4: Recurrent Neural Networks</h1>-->
        <h2>Provisional</h2>
        <p>The content of this page is provisional and will possibly change by the day of the lab.</p>
        <h2>Objectives</h2>
        <p>The objectives of this assignment are to:</p>
        <ul>
            <li>Write a program to recognize named entities in text</li>
            <li>Learn how to manage a text data set</li>
            <li>Apply recurrent neural networks to text</li>
            <li>Know what word embeddings are</li>
            <li>Write a short report on your experiments. This report is mandatory to pass the
                assignment.
            </li>
        </ul>
        <h2>Organization and location</h2>
        <p>The third lab session will take place on</p>
        <ul>
            <li>Groups 1 and 2: Thursday, November 28 from 13:15 to 15:00 in the Alpha and Beta rooms</li>
            <li>Groups 3 and 4: Friday, November 29 from 13:15 to 15:00 in the Alpha and Beta rooms</li>
        </ul>
        <p>Always check the calender for last minute changes:
            <a href="https://cloud.timeedit.net/lu/web/lth1/ri1Xp0gQ4560YZQQ85Z697wY0Zy70073Q5o53Q664v54rZo0xoQY.html#">
                https://cloud.timeedit.net/lu/web/lth1/ri1Xp0gQ4560YZQQ85Z697wY0Zy70073Q5o53Q664v54rZo0xoQY.html#
            </a>
        </p>
        <p>You can work alone or collaborate with another student:</p>
        <ul>
            <li>Each group will have to write Python programs to recognize named entities in text.
            </li>
            <li>You will have to experiment different architectures, namely RNN and LSTM,
                and compare the results you obtained.
            </li>
            <li>Each student will have to write an individual report on these experiments.</li>
        </ul>
        <h2>Programming</h2>
        <h3>Collecting a Dataset</h3>
        <ol>
            <li>You will use a dataset from the CoNLL conferences that benchmark natural language processing systems and
                tasks.
                There were two conferences on named entity recognition:
                <a href="https://www.clips.uantwerpen.be/conll2002/ner/">CoNLL 2002</a>
                (Spanish and Dutch)
                and <a href="https://www.clips.uantwerpen.be/conll2003/ner/">CoNLL 2003</a> (English and German). In
                this
                assignment, you will work on the English dataset. Read the description of the task.
            </li>
            <li>
                The datasets are protected by a license and you need to obtain it to reconstruct the data.
                Alternatively, you can use a local copy or try to find one on github (type conll2003 in the search box)
                or use the Google dataset search:
                <a href="https://toolbox.google.com/datasetsearch">https://toolbox.google.com/datasetsearch</a>.
                You can find a local copy in the <tt>/usr/local/cs/EDAN95/datasets/NER-data</tt> folder.
            </li>
            <li>The dataset comes in the form of three files: a training set, a development set, and a test set.
                <!--, named:
                <tt>eng.train</tt>, <tt>eng.testa</tt> (validation), and <tt>eng.testb</tt> (test).-->
                You will use the test set to evaluate your models. For this, you will
                apply the <tt>conlleval</tt> script that will compute the harmonic mean of the precision and recall: F1.
                You have a local copy of this script in <tt>/usr/local/cs/EDAN95/datasets/ner/bin</tt>. <tt>conlleval
                </tt> is
                written in Perl. Be sure to have it on your machine to run it.
            </li>
        </ol>
        <h3>Collecting the Embeddings</h3>
        <ol>
            <li>
                Download the GloVe embeddings 6B from
                <a href="https://nlp.stanford.edu/projects/glove/">
                    https://nlp.stanford.edu/projects/glove/
                </a>
                and keep the 100d vectors.
            </li>
            <li>
                You have a local copy of this script in <tt>/usr/local/cs/EDAN95/datasets/</tt>;
            </li>
            <li>Write a function that reads GloVe embeddings and store them in a dictionary,
                where the keys will be the words and the values, the embeddings.
            </li>
            <li>Using a cosine similarity, compute the 5 closest words to the words <i>table</i>, <i>france</i>,
                and <i>sweden</i>.
            </li>
        </ol>
        <h3>Reading the Corpus and Building Indices</h3>
        <p>You will read the corpus with programs available from
            <a href="https://github.com/pnugues/edan95">https://github.com/pnugues/edan95</a>. These
            programs will enable you to load the files in the form of a list of dictionaries.
        </p>
        <ol>
            <li>Write a function that for each sentence
                returns the <b>x</b> and <b>y</b> lists of symbols consisting of words and NER tags.
                For the second sentence of the training set, you should have:<br/>
                <tt>x = ['eu', 'rejects', 'german', 'call', 'to', 'boycott', 'british', 'lamb', '.']</tt><br/>
                <tt>y = ['I-ORG', 'O', 'I-MISC', 'O', 'O', 'O', 'I-MISC', 'O', 'O']</tt><br/>
                Some datasets you may find on the web use a different NER tagset, where <tt>I-</tt> is
                replaced with <tt>B-</tt>, like
                <tt>B-ORG</tt> instead of <tt>I-ORG</tt>. This will not change the results.
            </li>
            <li>
                Apply this function to your datasets so that you create <b>X</b> and <b>Y</b> lists
                of lists consisting of words and NER tags
            </li>
            <li>
                Create a vocabulary of all the words
                observed in the training set and the words in GloVe. You should find 402,595 different words.
            </li>
            <li>Create indices and inverted indices for the words and the NER: i.e. you
                will associate each word with a number.
                You will use index 0 for the padding symbol and 1 for unknown words.
            </li>
        </ol>
        <h3>Building the Embedding Matrix</h3>
        <ol>
            <li>Create a matrix of dimensions (<i>M</i>, <i>N</i>), where <i>M</i>, will the size of the vocabulary:
                The unique words in the training set and the words in GloVe, and <i>N</i>, the dimension of the embeddings.<br/>
                The padding symbol and the unknown word symbol will be part of the vocabulary.<br/>
                The shape of your matrix should be: (402597, 100). Initialize it with random values.
            </li>
            <li>Fill the matrix with the GloVe embeddings when available.
                You will use the indices from the previous section.
            </li>
        </ol>
        <h3>Creating the <b>X</b> and <b>Y</b> Sequences
        </h3>
        <p>You will now create the input and output sequences with numerical indices</p>
        <ol>
            <li>Convert the <b>X</b> and <b>Y</b> lists of symbols in lists of numbers using the indices
                you created.
            </li>
            <li>Pad the sentences using the <tt>pad_sequences</tt> function. As maximum length and
                <tt>maxlen</tt> argument, you will use 150 or greater. What matters is that you have a length that is larger than
                the maximum length observed in your training and development corpora.
                After padding, the second sentence you look like (the indices are not necessarily the same).
                <pre>
x = [     0      0      0      0      0      0      0      0      0      0
      0      0      0      0      0      0      0      0      0      0
      0      0      0      0      0      0      0      0      0      0
      0      0      0      0      0      0      0      0      0      0
      0      0      0      0      0      0      0      0      0      0
      0      0      0      0      0      0      0      0      0      0
      0      0      0      0      0      0      0      0      0      0
      0      0      0      0      0      0      0      0      0      0
      0      0      0      0      0      0      0      0      0      0
      0      0      0      0      0      0      0      0      0      0
      0      0      0      0      0      0      0      0      0      0
      0      0      0      0      0      0      0      0      0      0
      0      0      0      0      0      0      0      0      0      0
      0      0      0      0      0      0      0      0      0      0
      0 142143 307143 161836  91321 363368  83766  85852 218260    936]
y = [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 9 6 9 9 9 6
 9 9]
                </pre>
            </li>
            <li>Do the same for the development set.</li>
        </ol>
        <h3>Building a Simple Recurrent Neural Network</h3>
        <ol>
            <li>Create a simple recurrent network and train a model with the training set.
                As layers, you will use <tt>Embedding</tt>, <tt>SimpleRNN</tt>, and <tt>Dense</tt>.
            </li>
            <li>Compile and fit your network. You will report the training and validation losses and accuracies and
                comment on the possible overfit.
            </li>
            <li>Apply your network to the test set and report the accuracy you obtained.
                You will use the <tt>evaluate</tt> method.
            </li>
        </ol>
        <h3>Evaluating your System</h3>
        <p>You will use the official script to evaluate the performance of your system</p>
        <ol>
            <li>Use the <tt>predict</tt> method to predict the tags of the whole test set
            </li>
            <li>Write your results in a file, where the two last columns will be the hand-annotated tag
                and the predicted tag. The fields must be separated by a space and each line must end with a new line:
                <tt>\n</tt>.
            </li>
            <li>
                If you save your results on a Windows machine, Python will use the default end-of-line sequence: <tt>\r\n</tt>.
                You will then need either to convert your file or to modify the way you save your file.
            </li>
            <li>Apply <tt>conlleval</tt> to your output. Report the F1 result.<br/>
                Be aware that <tt>conlleval</tt> was designed for Unix and will break
            with Windows end-of-line conventions.</li>
            <li>Try to improve your model by modifying some parameters, adding layers, adding
                <tt>Bidirectional</tt>
                and <tt>Dropout</tt>.
            </li>
            <li>
                Evaluate your network again
            </li>
        </ol>
        <h3>Building a LSTM Network</h3>
        <ol>
            <li>Create a simple LSTM network and train a model with the train set.
                As layers, you will use <tt>Embedding</tt>, <tt>LSTM</tt>, and <tt>Dense</tt>.
            </li>
            <li>Apply conlleval to your output. Report the F1 result.</li>
            <li>Try to improve your model by modifying some parameters, adding layers, adding
                <tt>Bidirectional</tt>, <tt>Dropout</tt>, possibly mixing <tt>SimpleRNN</tt>.
            </li>
            <li>
                Apply your network to the test set and report the accuracy you obtained.
                you need to reach a F1 of 82 to pass.
            </li>
        </ol>
        <h2>Report</h2>
        <p>You will write a report of about two pages on your experiments:</p>
        <ol>
            <li>You will describe the architectures you designed and the results you obtained;</li>
            <li>You will read the article, <a href="https://www.aclweb.org/anthology/C18-1139"><i>Contextual String
            Embeddings for Sequence Labeling</i></a> by Akbik et al. (2018)
            and you will outline the main differences between their system and yours. You will tell the performance
            they reached on the corpus you used in this laboratory. This part should be of about one page.</li>
        </ol>

        <p>To write the report, you will use Overleaf.com. The submission procedure is described here:
            <a href="http://cs.lth.se/edan95/lab-programming-assignments/">http://cs.lth.se/edan95/lab-programming-assignments/</a>,
        but send me the Overleaf link only.</p>
        <!--<p>    and you will send the link to your report
        to the course address: edan95@cs.lth.se. Do not send the PDF, only the link. You will include
        the assignment number in the message object.</p>-->
        <p>You must submit this report no later than one week after you have complete the lab.</p>
    </body>
</html>
